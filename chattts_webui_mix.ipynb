{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "> 🌟 如果你觉得 ChatTTS 和 ChatTTS_colab 项目对你有帮助，请访问以下链接给它们点个星星吧！🌟\n",
        "\n",
        "- [ChatTTS 项目](https://github.com/2noise/ChatTTS)\n",
        "\n",
        "- [ChatTTS_colab 项目](https://github.com/6drf21e/ChatTTS_colab)\n",
        "\n",
        "感谢你的支持！\n",
        "\n",
        "# 运行方法\n",
        "\n",
        "- 点击菜单栏的--代码执行程序--全部运行即可\n",
        "- 执行后在下方的日志中找到类似\n",
        "\n",
        "  Running on public URL: https://**************.gradio.live  <-这个就是可以访问的公网地址\n",
        "\n",
        "安装包的时候提示要重启 请点**\"否\"**"
      ],
      "metadata": {
        "id": "Xo3k5XsTzWK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -q https://github.com/6drf21e/ChatTTS_colab\n",
        "%cd ChatTTS_colab\n",
        "!git clone -q https://github.com/2noise/ChatTTS\n",
        "%cd ChatTTS\n",
        "!git checkout -q e6412b1\n",
        "%cd ..\n",
        "!mv ChatTTS abc\n",
        "!mv abc/* /content/ChatTTS_colab/\n",
        "!pip install -q omegaconf vocos vector_quantize_pytorch gradio cn2an pypinyin openai jieba WeTextProcessing python-dotenv\n",
        "# 启动 Gradio 有公网地址\n",
        "!python webui_mix.py --share\n"
      ],
      "metadata": {
        "id": "hNDl-5muR77-",
        "outputId": "f81e4d33-cb63-4c13-db91-404ba9cd443d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ChatTTS_colab\n",
            "/content/ChatTTS_colab/ChatTTS\n",
            "/content/ChatTTS_colab\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.0/837.0 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m132.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "2025-04-18 14:44:16.142489: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744987456.364941    2110 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744987456.426244    2110 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-18 14:44:16.908784: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading ChatTTS model...\n",
            "INFO:ChatTTS.core:Download from HF: https://huggingface.co/2Noise/ChatTTS\n",
            "Fetching 12 files:   0% 0/12 [00:00<?, ?it/s]\n",
            "Decoder.pt:   0% 0.00/104M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "spk_stat.pt: 100% 4.26k/4.26k [00:00<00:00, 22.2MB/s]\n",
            "\n",
            "\n",
            "Vocos.pt:   0% 0.00/54.4M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:   0% 0.00/901M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "DVAE_full.pt:   0% 0.00/60.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.pt: 100% 337k/337k [00:00<00:00, 6.43MB/s]\n",
            "\n",
            "\n",
            "Vocos.pt:  19% 10.5M/54.4M [00:00<00:00, 67.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "dvae.yaml: 100% 143/143 [00:00<00:00, 803kB/s]\n",
            "\n",
            "Decoder.pt:  10% 10.5M/104M [00:00<00:01, 53.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:   1% 10.5M/901M [00:00<00:15, 56.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "decoder.yaml: 100% 117/117 [00:00<00:00, 676kB/s]\n",
            "\n",
            "\n",
            "Vocos.pt:  39% 21.0M/54.4M [00:00<00:00, 82.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:   2% 21.0M/901M [00:00<00:13, 66.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "DVAE_full.pt:  17% 10.5M/60.4M [00:00<00:01, 33.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Decoder.pt:  20% 21.0M/104M [00:00<00:01, 62.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gpt.yaml: 100% 346/346 [00:00<00:00, 2.28MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "path.yaml: 100% 309/309 [00:00<00:00, 1.86MB/s]\n",
            "\n",
            "\n",
            "Vocos.pt:  58% 31.5M/54.4M [00:00<00:00, 72.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "vocos.yaml: 100% 460/460 [00:00<00:00, 2.87MB/s]\n",
            "\n",
            "Decoder.pt:  30% 31.5M/104M [00:00<00:00, 73.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "DVAE_full.pt:  35% 21.0M/60.4M [00:00<00:00, 50.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DVAE.pt:   0% 0.00/27.7M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:   5% 41.9M/901M [00:00<00:10, 79.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Decoder.pt:  40% 41.9M/104M [00:00<00:00, 79.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "DVAE_full.pt:  52% 31.5M/60.4M [00:00<00:00, 60.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Vocos.pt:  96% 52.4M/54.4M [00:00<00:00, 83.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:   6% 52.4M/901M [00:00<00:10, 80.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "DVAE_full.pt:  69% 41.9M/60.4M [00:00<00:00, 69.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Vocos.pt: 100% 54.4M/54.4M [00:00<00:00, 74.9MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DVAE.pt:  38% 10.5M/27.7M [00:00<00:00, 34.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "DVAE_full.pt:  87% 52.4M/60.4M [00:00<00:00, 78.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Decoder.pt:  61% 62.9M/104M [00:00<00:00, 80.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:   8% 73.4M/901M [00:00<00:09, 90.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Decoder.pt:  71% 73.4M/104M [00:00<00:00, 84.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DVAE.pt:  76% 21.0M/27.7M [00:00<00:00, 49.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "DVAE_full.pt: 100% 60.4M/60.4M [00:00<00:00, 61.2MB/s]\n",
            "DVAE.pt: 100% 27.7M/27.7M [00:00<00:00, 49.8MB/s]\n",
            "\n",
            "Decoder.pt: 100% 104M/104M [00:01<00:00, 91.6MB/s]\n",
            "\n",
            "\n",
            "\n",
            "GPT.pt:  12% 105M/901M [00:01<00:07, 109MB/s]  \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  15% 136M/901M [00:01<00:04, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  19% 168M/901M [00:01<00:04, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  21% 189M/901M [00:01<00:03, 182MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  24% 220M/901M [00:01<00:03, 192MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  27% 241M/901M [00:01<00:03, 195MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  29% 262M/901M [00:01<00:03, 199MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  31% 283M/901M [00:01<00:03, 200MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  35% 315M/901M [00:02<00:02, 204MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  37% 336M/901M [00:02<00:02, 201MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  41% 367M/901M [00:02<00:02, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  44% 398M/901M [00:02<00:02, 209MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  47% 419M/901M [00:02<00:02, 209MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  50% 451M/901M [00:02<00:02, 209MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  54% 482M/901M [00:02<00:02, 209MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  56% 503M/901M [00:02<00:01, 209MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  59% 535M/901M [00:03<00:01, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  63% 566M/901M [00:03<00:01, 210MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  66% 598M/901M [00:03<00:01, 209MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  69% 619M/901M [00:03<00:01, 209MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  71% 640M/901M [00:03<00:01, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  75% 671M/901M [00:03<00:01, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  78% 703M/901M [00:03<00:00, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  80% 724M/901M [00:04<00:00, 209MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  83% 744M/901M [00:04<00:00, 209MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  85% 765M/901M [00:04<00:00, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  87% 786M/901M [00:04<00:00, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  91% 818M/901M [00:04<00:00, 209MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  93% 839M/901M [00:04<00:00, 205MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt:  97% 870M/901M [00:04<00:00, 209MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "GPT.pt: 100% 901M/901M [00:04<00:00, 183MB/s]\n",
            "Fetching 12 files: 100% 12/12 [00:05<00:00,  2.35it/s]\n",
            "INFO:ChatTTS.core:use cuda:0\n",
            "INFO:ChatTTS.core:vocos loaded.\n",
            "INFO:ChatTTS.core:dvae loaded.\n",
            "INFO:ChatTTS.core:gpt loaded.\n",
            "INFO:ChatTTS.core:decoder loaded.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ChatTTS_colab/webui_mix.py\", line 46, in <module>\n",
            "    chat = load_chat_tts_model(source=args.source, local_path=args.local_path)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ChatTTS_colab/tts_model.py\", line 25, in load_chat_tts_model\n",
            "    chat.load_models(source=source, force_redownload=force_redownload, custom_path=local_path, compile=False)\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 81, in load_models\n",
            "    self._load(**{k: os.path.join(download_path, v) for k, v in OmegaConf.load(os.path.join(download_path, 'config', 'path.yaml')).items()}, **kwargs)\n",
            "  File \"/content/ChatTTS_colab/ChatTTS/core.py\", line 144, in _load\n",
            "    tokenizer = torch.load(tokenizer_path, map_location='cpu')\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1470, in load\n",
            "    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n",
            "_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL transformers.models.bert.tokenization_bert_fast.BertTokenizerFast was not an allowed global by default. Please use `torch.serialization.add_safe_globals([BertTokenizerFast])` or the `torch.serialization.safe_globals([BertTokenizerFast])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n"
          ]
        }
      ]
    }
  ]
}